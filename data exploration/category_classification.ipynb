{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea:\n",
    "- Take in a description of the ticket as well as the issue type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack, csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16642/3375834500.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\", \n",
    "    user=\"root\", \n",
    "    password=\"password1\", \n",
    "    host=\"localhost\", \n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "# Define your SQL query\n",
    "query = 'SELECT * FROM \"Issue\"'\n",
    "\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "# print(df.head())\n",
    "\n",
    "\n",
    "# Define the column mapping\n",
    "column_mapping = {\n",
    "    \"Summary\": \"summary\",\n",
    "    \"Issue key\": \"issueKey\",\n",
    "    \"Issue id\": \"issueId\",\n",
    "    \"Issue Type\": \"issueType\",\n",
    "    \"Status\": \"status\",\n",
    "    \"Project key\": \"projectKey\",\n",
    "    \"Project name\": \"projectName\",\n",
    "    \"Priority\": \"priority\",\n",
    "    \"Resolution\": \"resolution\",\n",
    "    \"Assignee\": \"assignee\",\n",
    "    \"Reporter (Email)\": \"reporterEmail\",\n",
    "    \"Creator (Email)\": \"creatorEmail\",\n",
    "    \"Created\": \"created\",\n",
    "    \"Updated\": \"updated\",\n",
    "    \"Last Viewed\": \"lastViewed\",\n",
    "    \"Resolved\": \"resolved\",\n",
    "    \"Due date\": \"dueDate\",\n",
    "    \"Description\": \"description\",\n",
    "    \"Partner Names\": \"partnerNames\",\n",
    "    \"Custom field (Cause of issue)\": \"causeOfIssue\",\n",
    "    \"Custom field (Record/Transaction ID)\": \"recordTransactionId\",\n",
    "    \"Custom field (Region)\": \"region\",\n",
    "    \"Custom field (Relevant Departments)\": \"relevantDepartments\",\n",
    "    \"Custom field (Relevant Departments).1\": \"relevantDepartments1\",\n",
    "    \"Custom field (Request Category)\": \"requestCategory\",\n",
    "    \"Custom field (Request Type)\": \"requestType\",\n",
    "    \"Custom field (Request language)\": \"requestLanguage\",\n",
    "    \"Custom field (Resolution Action)\": \"resolutionAction\",\n",
    "    \"Satisfaction rating\": \"satisfactionRating\",\n",
    "    \"Custom field (Satisfaction date)\": \"satisfactionDate\",\n",
    "    \"Custom field (Source)\": \"source\",\n",
    "    \"Custom field (Time to first response)\": \"timeToFirstResponse\",\n",
    "    \"Custom field (Time to resolution)\": \"timeToResolution\",\n",
    "    \"Custom field (Work category)\": \"workCategory\",\n",
    "    \"Status Category\": \"statusCategory\",\n",
    "    \"Status Category Changed\": \"statusCategoryChanged\",\n",
    "    \"Custom field ([CHART] Date of First Response)\": \"dateOfFirstResponse\",\n",
    "    \"comments\": \"comments\"\n",
    "}\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "df.rename(columns=column_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'Request of Customer Relations' 'Other' 'Partner Error' 'Ops Issue'\n",
      " 'Partner Knowledge/Training' 'Menu Discrepancy' 'System Error']\n",
      "['General Questions' 'Email Request' 'Website Assistance (PartnerLink)'\n",
      " 'Pickup & Delivery Support' 'Request New Shopper Access'\n",
      " 'Revise My Order' 'Request Produce' 'Grant Support' 'Billing Support'\n",
      " 'Provide Menu Feedback' 'Request a Return or Refund'\n",
      " 'Questions about Shopping Menu Items'\n",
      " 'Provide Operations/Transportation Feedback']\n",
      "['' 'Orders - Pre delivery -> Cancelation'\n",
      " 'Orders - Pre delivery -> Produce Request'\n",
      " 'Orders - Pre delivery -> General Questions'\n",
      " 'Orders - Pre delivery -> Edit Order Items'\n",
      " 'Billing / Grants -> Grant Support'\n",
      " 'Agency Administration -> Connection to CAFB Staff'\n",
      " 'Orders - Pre delivery' 'Delivery / Pickup -> Return - Quality'\n",
      " 'PartnerLink -> New Shopper' 'Delivery / Pickup -> General Questions'\n",
      " 'Orders - Pre delivery -> Report Issue'\n",
      " 'Orders - Pre delivery ->  Date/Time Change - New window'\n",
      " 'Delivery / Pickup -> Pallet Pickup'\n",
      " 'Orders - Pre delivery -> Data/Time Change - Reschedule'\n",
      " 'Menu -> Discrepancy' 'Agency Administration -> Partner Trainings'\n",
      " 'Feedback - Concern / Negative -> Transportation'\n",
      " 'Partner Produce Limit -> Overage Alert'\n",
      " 'Feedback - Concern / Negative -> Operations'\n",
      " 'Billing / Grants -> Questions for Accounting' 'Delivery / Pickup'\n",
      " 'Delivery / Pickup -> Missing Item - Redeliver'\n",
      " 'PartnerLink -> General Questions'\n",
      " 'Agency Administration -> Update Information'\n",
      " 'Menu -> Inventory Availability'\n",
      " 'Menu -> Product Best By / Expiration Date'\n",
      " 'Orders - Pre delivery ->  Change to Pickup/vice versa'\n",
      " 'Delivery / Pickup -> Report Issue'\n",
      " 'Partner Produce Limit -> Question or Concern'\n",
      " 'Billing / Grants -> Discrepancy in Invoice' 'Menu -> General Questions'\n",
      " 'Delivery / Pickup -> Missing Item - Refund'\n",
      " 'Delivery / Pickup -> Request ETA / Status'\n",
      " 'Orders - Pre delivery ->  Request unavailable window' 'PartnerLink'\n",
      " 'Billing / Grants -> General Questions'\n",
      " 'Spam / Duplicate -> Spam / Duplicate'\n",
      " 'Feedback - Positive -> Transportation' 'PartnerLink -> ERP Issue'\n",
      " 'Feedback - Concern / Negative -> Other / General'\n",
      " 'Agency Administration'\n",
      " 'Feedback - Concern / Negative -> Quality - Non Produce'\n",
      " 'Feedback - Concern / Negative -> Quality - Produce' 'Spam / Duplicate'\n",
      " 'Return Notification -> Daily Report'\n",
      " 'Feedback - Concern / Negative -> Menu'\n",
      " 'Agency Administration -> Office Hours'\n",
      " 'Delivery / Pickup -> Return - Not Ordered']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"causeOfIssue\"].unique())\n",
    "\n",
    "print(df[\"requestType\"].unique())\n",
    "\n",
    "print(df[\"requestCategory\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ticket(ticket_data, model, vectorizer, label_encoders):\n",
    "    \"\"\"\n",
    "    Uses an ML model to classify a ticket based on multiple fields.\n",
    "    :param ticket_data: A dictionary with ticket fields.\n",
    "    :param model: The trained classification model.\n",
    "    :param vectorizer: The vectorizer for text transformation.\n",
    "    :param label_encoders: Dictionary of label encoders for categorical fields.\n",
    "    :return: The predicted category of the ticket.\n",
    "    \"\"\"\n",
    "    text_features = vectorizer.transform([ticket_data[\"Summary\"] + \" \" + ticket_data[\"Description\"]])\n",
    "    cat_features = hstack([\n",
    "        label_encoders[\"causeOfIssue\"].transform([ticket_data[\"causeOfIssue\"]]).reshape(-1, 1),\n",
    "        label_encoders[\"requestType\"].transform([ticket_data[\"requestType\"]]).reshape(-1, 1)\n",
    "    ])\n",
    "    features = hstack([text_features, cat_features])\n",
    "    return model.predict(features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdd to Order\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCancel Order\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChange Order\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck Status\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRefund Request\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2564\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 5]"
     ]
    }
   ],
   "source": [
    "label_encoders = {col: LabelEncoder().fit(df[col]) for col in [\"causeOfIssue\", \"requestType\"]}\n",
    "df[\"causeOfIssue\"] = label_encoders[\"causeOfIssue\"].transform(df[\"causeOfIssue\"])\n",
    "df[\"requestType\"] = label_encoders[\"requestType\"].transform(df[\"requestType\"])\n",
    "\n",
    "# Vectorize text fields\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_text = vectorizer.fit_transform(df[\"summary\"] + \" \" + df[\"description\"])\n",
    "X_cat = csr_matrix(df[[\"causeOfIssue\", \"requestType\"]].values)\n",
    "X = hstack([X_text, X_cat])\n",
    "df[\"category\"] = None\n",
    "y = [\"Add to Order\", \"Cancel Order\", \"Change Order\", \"Check Status\", \"Refund Request\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Example Usage\n",
    "ticket_example = {\n",
    "    \"Summary\": \"Modify my order details\",\n",
    "    \"Description\": \"I need to update my delivery address.\",\n",
    "    \"causeOfIssue\": \"Address Change\",\n",
    "    \"requestType\": \"Change Order\"\n",
    "}\n",
    "\n",
    "print(f\"Predicted Category: {classify_ticket(ticket_example, model, vectorizer, label_encoders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
